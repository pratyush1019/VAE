{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "train_data = datasets.MNIST(root='./data_mnist/train/', train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_data = datasets.MNIST(root='./mnist_data/test/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "tr = torch.utils.data.DataLoader(dataset=train_data, batch_size=8, shuffle=True)\n",
    "tst = torch.utils.data.DataLoader(dataset=test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_enc1 (784, 640)\n",
      "linear_enc2 (640, 320)\n",
      "linear_enc3 (320, 80)\n",
      "linear_enc5_mean (80, 20)\n",
      "linear_enc5_std (80, 20)\n",
      "linear_dec4 (20, 80)\n",
      "linear_dec3 (80, 320)\n",
      "linear_dec2 (320, 640)\n",
      "linear_dec1 (640, 784)\n"
     ]
    }
   ],
   "source": [
    "from model import VAE,VAEloss\n",
    "\n",
    "layers = [784,640,320,80,20]\n",
    "vae = VAE(layers)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "vae.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "criterion = VAEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,     1) item-loss: 4354.654785156\n",
      "(1,    41) item-loss: 1981.650512695\n",
      "(1,    81) item-loss: 1543.547241211\n",
      "(1,   121) item-loss: 1679.371215820\n",
      "(1,   161) item-loss: 1789.319946289\n",
      "(1,   201) item-loss: 1644.952392578\n",
      "(1,   241) item-loss: 1349.015869141\n",
      "(1,   281) item-loss: 1624.691894531\n",
      "(1,   321) item-loss: 1610.260986328\n",
      "(1,   361) item-loss: 1578.882934570\n",
      "(1,   401) item-loss: 1445.746948242\n",
      "(1,   441) item-loss: 1583.377441406\n",
      "(1,   481) item-loss: 1613.934448242\n",
      "(1,   521) item-loss: 1515.623168945\n",
      "(1,   561) item-loss: 1736.087280273\n",
      "(1,   601) item-loss: 1526.037109375\n",
      "(1,   641) item-loss: 1449.536987305\n",
      "(1,   681) item-loss: 1622.219604492\n",
      "(1,   721) item-loss: 1352.725341797\n",
      "(1,   761) item-loss: 1303.525634766\n",
      "(1,   801) item-loss: 1571.272216797\n",
      "(1,   841) item-loss: 1308.579101562\n",
      "(1,   881) item-loss: 1347.767700195\n",
      "(1,   921) item-loss: 1602.302246094\n",
      "(1,   961) item-loss: 1291.191772461\n",
      "(1,  1001) item-loss: 1353.031616211\n",
      "(1,  1041) item-loss: 1361.282348633\n",
      "(1,  1081) item-loss: 1130.204956055\n",
      "(1,  1121) item-loss: 1293.125366211\n",
      "(1,  1161) item-loss: 1510.022705078\n",
      "(1,  1201) item-loss: 1226.410522461\n",
      "(1,  1241) item-loss: 1122.020629883\n",
      "(1,  1281) item-loss: 1330.362426758\n",
      "(1,  1321) item-loss: 1480.653442383\n",
      "(1,  1361) item-loss: 1135.959106445\n",
      "(1,  1401) item-loss: 1387.356323242\n",
      "(1,  1441) item-loss: 1262.630859375\n",
      "(1,  1481) item-loss: 1066.293701172\n",
      "(1,  1521) item-loss: 1198.428710938\n",
      "(1,  1561) item-loss: 1347.572631836\n",
      "(1,  1601) item-loss: 1013.796081543\n",
      "(1,  1641) item-loss: 1480.034423828\n",
      "(1,  1681) item-loss: 1517.488647461\n",
      "(1,  1721) item-loss: 1337.679687500\n",
      "(1,  1761) item-loss: 1303.018798828\n",
      "(1,  1801) item-loss: 1303.281250000\n",
      "(1,  1841) item-loss: 1188.221191406\n",
      "(1,  1881) item-loss: 1247.954589844\n",
      "(1,  1921) item-loss: 1305.217895508\n",
      "(1,  1961) item-loss: 1253.732055664\n",
      "(1,  2001) item-loss: 1166.133300781\n",
      "(1,  2041) item-loss: 1302.576293945\n",
      "(1,  2081) item-loss: 1360.570312500\n",
      "(1,  2121) item-loss: 1357.027099609\n",
      "(1,  2161) item-loss: 1174.923095703\n",
      "(1,  2201) item-loss: 1006.722351074\n",
      "(1,  2241) item-loss: 1222.075683594\n",
      "(1,  2281) item-loss: 1294.467285156\n",
      "(1,  2321) item-loss: 1226.361450195\n",
      "(1,  2361) item-loss: 1329.148071289\n",
      "(1,  2401) item-loss: 1245.491943359\n",
      "(1,  2441) item-loss: 1309.651611328\n",
      "(1,  2481) item-loss: 1162.104125977\n",
      "(1,  2521) item-loss: 1046.022094727\n",
      "(1,  2561) item-loss: 960.554382324\n",
      "(1,  2601) item-loss: 1048.509155273\n",
      "(1,  2641) item-loss: 1220.223632812\n",
      "(1,  2681) item-loss: 1012.226257324\n",
      "(1,  2721) item-loss: 1111.822631836\n",
      "(1,  2761) item-loss: 756.915527344\n",
      "(1,  2801) item-loss: 820.114990234\n",
      "(1,  2841) item-loss: 1321.127075195\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6fe6fe1e6fbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(%d, %5d) item-loss: %.9f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[%d] epoch-loss: %.9f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "# acc_history = []\n",
    "for epoch in range(50):\n",
    "    train_loss = 0.0\n",
    "    for i,data in enumerate(tr):\n",
    "        x, y = data\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, mean, logstd = vae(x.view(-1,784))\n",
    "        loss = criterion(y_pred, x.view(-1,784), mean, logstd)\n",
    "        x = loss.item()\n",
    "        train_loss += x\n",
    "        if (i%40==0):\n",
    "            print('(%d, %5d) item-loss: %.9f'%(epoch + 1, i + 1, x))\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "    print('[%d] epoch-loss: %.9f'%(epoch + 1, train_loss))\n",
    "    loss_history.append(train_loss)\n",
    "#     acc_history.append(get_accuracy())\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving the model\n",
    "PATH = 'vae_mnist.pth'\n",
    "torch.save(vae.state_dict(), PATH)\n",
    "##loading the model\n",
    "model = vae(layers)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Variable(torch.randn(128, 20))\n",
    "recon_x = vae.decode(sample)\n",
    "\n",
    "save_image(recon_x.view(recon_x.size(0), 1, 28, 28).data.cpu(), 'sample_image.png')\n",
    "Image('sample_image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
